{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpic_uLZ0dOa",
        "outputId": "13aedecb-62bd-469f-c4c8-2ad3d335e1e5"
      },
      "outputs": [],
      "source": [
        "# # %pip install python-csv\n",
        "# !pip install nltk\n",
        "# !pip install scikit-learn\n",
        "# !pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x4EYcSts0dOb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Lucifer-Drive\\Programs\\SBD_model\\ev_ker\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import joblib\n",
        "import os\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCbPb-Kw0dOb",
        "outputId": "2643a026-67ce-402e-b55a-571dfbb57586"
      },
      "outputs": [],
      "source": [
        "def load_necessary_lib():\n",
        "    \"\"\"\n",
        "    Load necessary libraries for the project\n",
        "    \"\"\"\n",
        "    # Preload NLTK data\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('punkt')\n",
        "    print(\"Libraries loaded successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "HmlGlPi30dOb",
        "outputId": "f78f132d-dd14-4191-8069-fc560a4f62fb"
      },
      "outputs": [],
      "source": [
        "def load_dataset_download(dataset_path=\"suicide_dataset.csv\"):\n",
        "    \"\"\"\n",
        "    loading dataset from the web if not present else , loading from the local directory\n",
        "    \"\"\"\n",
        "    # Load the dataset if not present\n",
        "    try:\n",
        "        if os.path.exists(dataset_path):\n",
        "            print(\"File exists\")\n",
        "        else:\n",
        "            dataset = load_dataset(\"Ram07/Detection-for-Suicide\")\n",
        "            df = pd.DataFrame(dataset['train'])\n",
        "            df.to_csv(dataset_path, index=False)\n",
        "    except Exception as e:\n",
        "        print(\"Error loading dataset:\", e)\n",
        "        sys.exit()\n",
        "\n",
        "    finally:\n",
        "        # Load data directly from the CSV file\n",
        "        try:\n",
        "            data = pd.read_csv(dataset_path)\n",
        "            print(f\"Database {dataset_path} loaded ...._\")\n",
        "            data = clean_na(data)\n",
        "            return clean_dataset(data)\n",
        "        except Exception as e:\n",
        "            print(\"Error loading dataset:\", e)\n",
        "            sys.exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
              "      <td>sex wife threaten suicide recently leave wife ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Am I weird I don't get affected by compliments...</td>\n",
              "      <td>weird not affect compliment come know real lif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
              "      <td>finally hear bad year swear fucking god annoying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>i need helpjust help me im crying so hard</td>\n",
              "      <td>need help just help cry hard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>It ends tonight.I can’t do it anymore. \\nI quit.</td>\n",
              "      <td>end tonight not anymore quit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   class                                               text  \\\n",
              "0      0  Ex Wife Threatening SuicideRecently I left my ...   \n",
              "1      1  Am I weird I don't get affected by compliments...   \n",
              "2      1  Finally 2020 is almost over... So I can never ...   \n",
              "3      0          i need helpjust help me im crying so hard   \n",
              "4      0   It ends tonight.I can’t do it anymore. \\nI quit.   \n",
              "\n",
              "                                        cleaned_text  \n",
              "0  sex wife threaten suicide recently leave wife ...  \n",
              "1  weird not affect compliment come know real lif...  \n",
              "2   finally hear bad year swear fucking god annoying  \n",
              "3                       need help just help cry hard  \n",
              "4                       end tonight not anymore quit  "
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File exists\n",
            "Database suicide_dataset.csv loaded ...._\n",
            "cleaning NA\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>text</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Ex Wife Threatening SuicideRecently I left my ...</td>\n",
              "      <td>sex wife threaten suicide recently leave wife ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Am I weird I don't get affected by compliments...</td>\n",
              "      <td>weird not affect compliment come know real lif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Finally 2020 is almost over... So I can never ...</td>\n",
              "      <td>finally hear bad year swear fucking god annoying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>i need helpjust help me im crying so hard</td>\n",
              "      <td>need help just help cry hard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>It ends tonight.I can’t do it anymore. \\nI quit.</td>\n",
              "      <td>end tonight not anymore quit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   class                                               text  \\\n",
              "0      0  Ex Wife Threatening SuicideRecently I left my ...   \n",
              "1      1  Am I weird I don't get affected by compliments...   \n",
              "2      1  Finally 2020 is almost over... So I can never ...   \n",
              "3      0          i need helpjust help me im crying so hard   \n",
              "4      0   It ends tonight.I can’t do it anymore. \\nI quit.   \n",
              "\n",
              "                                        cleaned_text  \n",
              "0  sex wife threaten suicide recently leave wife ...  \n",
              "1  weird not affect compliment come know real lif...  \n",
              "2   finally hear bad year swear fucking god annoying  \n",
              "3                       need help just help cry hard  \n",
              "4                       end tonight not anymore quit  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def clean_dataset(dataset):\n",
        "    binary_convert = lambda x: 0 if x == \"suicide\" else 1\n",
        "    # data=pd.read_csv(\"suicide_dataset.csv\")\n",
        "    dataset['class'] = dataset['class'].apply(binary_convert)\n",
        "    return dataset\n",
        "\n",
        "# load_dataset_download().head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "CmnD5MWj0dOb"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"Preprocess the text data\n",
        "    >>> preprocess_text(\"took rest sleeping pills painkillers i want to end struggle of past 6 years\")\n",
        "    >>> \"took rest sleeping pills painkillers want end struggle past 6 years\"  # <----- this is in the str format\n",
        "    \"\"\"\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = nltk.word_tokenize(text.lower())  # Tokenization and convert to lowercase\n",
        "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "    return ' '.join(filtered_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VFlMFmi90dOc"
      },
      "outputs": [],
      "source": [
        "def train_model_SDM(X_train, y_train):\n",
        "    # Train a classification model\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    classifier = SVC(kernel='linear', verbose=True, probability=True)  # Enable probability estimates\n",
        "    model = make_pipeline(vectorizer, classifier)\n",
        "    model.fit(X_train, y_train)\n",
        "    print(\"Model trained successfully.\")\n",
        "    save_model(model)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PuDbiqVC0dOc"
      },
      "outputs": [],
      "source": [
        "def save_model(model):     \n",
        "    # Save the trained model\n",
        "    try:\n",
        "        joblib.dump(model, 'suicide_detection_model.pkl')\n",
        "        print(\"Model saved successfully.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error saving model:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_VMFihXe0dOc"
      },
      "outputs": [],
      "source": [
        "def clean_na(data):\n",
        "    # Remove rows with NaN values\n",
        "    cleaned_data = data.dropna()\n",
        "    print(\"cleaning NA\")\n",
        "    return cleaned_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nokoDUmj0dOc"
      },
      "outputs": [],
      "source": [
        "def start_model(X_train, y_train, train_model=False):\n",
        "    print('start_model'.center(120, \"-\"))\n",
        "    if not train_model and os.path.exists(\"suicide_detection_model.pkl\"):\n",
        "        # Load the saved model\n",
        "        try:\n",
        "            model = joblib.load('suicide_detection_model.pkl')\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            print(\"Error loading the model:\", e)\n",
        "    else:\n",
        "        model = train_model_SDM(X_train, y_train)\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rFS7w-nQ3qx_"
      },
      "outputs": [],
      "source": [
        "def preprocess_text_with_progress(data, text_column='text', label_column='class', save_file=None):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def preprocess_text(text):\n",
        "        if pd.isna(text):  # Check for NaN values\n",
        "            return ''  # Replace NaN values with an empty string\n",
        "        tokens = nltk.word_tokenize(text.lower())\n",
        "        filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "        return ' '.join(filtered_tokens)\n",
        "\n",
        "    tqdm.pandas(desc=\"Preprocessing Text\")\n",
        "    processed_text = data[text_column].progress_apply(preprocess_text)\n",
        "    \n",
        "    # Combine preprocessed text with labels\n",
        "    processed_data = pd.concat([processed_text, data[label_column]], axis=1)\n",
        "\n",
        "    if save_file:\n",
        "        processed_data.to_csv(save_file, index=False)\n",
        "\n",
        "    return processed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rlDjkDaH4FNF"
      },
      "outputs": [],
      "source": [
        "def evaluating_SDM(model, X_test, y_test):\n",
        "    # Remove samples with NaN labels\n",
        "    X_test = X_test[~y_test.isna()]\n",
        "    y_test = y_test.dropna()\n",
        "\n",
        "    # Evaluate the model on the test set with a spinning animation\n",
        "    with tqdm(total=len(X_test), desc=\"Evaluating Model\", bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt} {postfix}\") as pbar:\n",
        "        for _ in range(len(X_test)):\n",
        "            time.sleep(0.1)  # Simulate evaluation time (remove in actual usage)\n",
        "            pbar.update(1)\n",
        "    \n",
        "    try:\n",
        "        accuracy = model.score(X_test, y_test)\n",
        "        print(\"\\nModel Accuracy on Test Set:\", round(accuracy * 100, 3), \"%\")\n",
        "    except Exception as e:\n",
        "        print(\"Error evaluating model:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "izncOgx26FZS"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    load_necessary_lib()\n",
        "    data = load_dataset_download(\"suicide_dataset.csv\")\n",
        "    print(\"------------>>>>> Data loaded <<<<<-----------\")\n",
        "\n",
        "    # Preprocess text\n",
        "    data_processed = preprocess_text_with_progress(data, text_column='text', label_column='class', save_file='final_cleaned_processed_text.csv')\n",
        "\n",
        "    # Split data into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data_processed['text'], data_processed['class'], test_size=0.2, random_state=42)\n",
        "    print(\"Data split done.\")\n",
        "\n",
        "    # Train or load the model\n",
        "    model = start_model(X_train, y_train, train_model=True)\n",
        "\n",
        "    # Evaluate the model\n",
        "    # evaluating_SDM(model, X_test, y_test)\n",
        "\n",
        "    \n",
        "    print(\"Running the user_response program\".center(120,\"_\"),\"\\n\")\n",
        "    cont = True\n",
        "    while cont:\n",
        "        # Accept user input\n",
        "        try:\n",
        "            user_input = input(\"Enter your response: \").strip()\n",
        "            if user_input == \"quit\":\n",
        "                cont = False\n",
        "            elif user_input:\n",
        "                # Preprocess user input\n",
        "                preprocessed_input = preprocess_text(user_input)\n",
        "\n",
        "                # Predict\n",
        "                prediction = model.predict([preprocessed_input])\n",
        "                print(\"Prediction Data:\", prediction)\n",
        "                \n",
        "                # Output prediction result\n",
        "                prediction_scores = model.predict_proba([preprocessed_input])[0]\n",
        "                print(\"Prediction Score for Suicidal:\", \"{}%\".format(round(prediction_scores[1] * 100,3)))\n",
        "                print(\"Prediction Score for Non-Suicidal:\", \"{:.2f}%\".format(round(prediction_scores[0] * 100,3)))\n",
        "                # Output prediction result\n",
        "                print(\"Prediction:\\t\\t>>\", prediction[0],\"<<\\n\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                print(\"Empty input. Please provide a response.\")\n",
        "        except Exception as e:\n",
        "            print(\"Error processing user input:\", e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "z2TJoYmx7JCw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\anton\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries loaded successfully\n",
            "File exists\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Database suicide_dataset.csv loaded ...._\n",
            "------------>>>>> Data loaded <<<<<-----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preprocessing Text: 100%|██████████| 174436/174436 [00:37<00:00, 4618.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data split done.\n",
            "------------------------------------------------------start_model-------------------------------------------------------\n",
            "___________________________________________Running the user_response program____________________________________________ \n",
            "\n",
            "Prediction Data: ['non-suicide']\n",
            "Prediction Score for Suicidal: 0.074%\n",
            "Prediction Score for Non-Suicidal: 99.93%\n",
            "Prediction:\t\t>> non-suicide <<\n",
            "Prediction Data: ['non-suicide']\n",
            "Prediction Score for Suicidal: 0.048%\n",
            "Prediction Score for Non-Suicidal: 99.95%\n",
            "Prediction:\t\t>> non-suicide <<\n",
            "Prediction Data: ['suicide']\n",
            "Prediction Score for Suicidal: 99.999%\n",
            "Prediction Score for Non-Suicidal: 0.00%\n",
            "Prediction:\t\t>> suicide <<\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    main()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nExiting the program.\")\n",
        "except Exception as e:\n",
        "    print(\"An error occurred:\", e)\n",
        "    sys.exit()  # Uncomment this line if you want to exit on error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from matplotlib import pyplot as plt\n",
        "# from sklearn.metrics import confusion_matrix , classification_report\n",
        "# import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
        "#     \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
        "    \n",
        "#     Arguments\n",
        "#     ---------\n",
        "#     confusion_matrix: numpy.ndarray\n",
        "#         The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
        "#         Similarly constructed ndarrays can also be used.\n",
        "#     class_names: list\n",
        "#         An ordered list of class names, in the order they index the given confusion matrix.\n",
        "#     figsize: tuple\n",
        "#         A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
        "#         the second determining the vertical size. Defaults to (10,7).\n",
        "#     fontsize: int\n",
        "#         Font size for axes labels. Defaults to 14.\n",
        "        \n",
        "#     Returns\n",
        "#     -------\n",
        "#     matplotlib.figure.Figure\n",
        "#         The resulting confusion matrix figure\n",
        "#     \"\"\"\n",
        "#     df_cm = pd.DataFrame(\n",
        "#         confusion_matrix, index=class_names, columns=class_names, \n",
        "#     )\n",
        "#     fig = plt.figure(figsize=figsize)\n",
        "#     try:\n",
        "#         heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
        "#     except ValueError:\n",
        "#         raise ValueError(\"Confusion matrix values must be integers.\")\n",
        "#     heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
        "#     heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
        "#     plt.ylabel('Truth')\n",
        "#     plt.xlabel('Prediction')\n",
        "# truth =      [\"Dog\",\"Not a dog\",\"Dog\",\"Dog\",      \"Dog\", \"Not a dog\", \"Not a dog\", \"Dog\",       \"Dog\", \"Not a dog\"]\n",
        "# prediction = [\"Dog\",\"Dog\",      \"Dog\",\"Not a dog\",\"Dog\", \"Not a dog\", \"Dog\",       \"Not a dog\", \"Dog\", \"Dog\"]\n",
        "# cm = confusion_matrix(truth,prediction)\n",
        "# print_confusion_matrix(cm,[\"Dog\",\"Not a dog\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# # Load the dataset\n",
        "# data = pd.read_csv('final_cleaned_processed_text.csv')\n",
        "\n",
        "# # Drop rows with NaN values\n",
        "# data.dropna(inplace=True)\n",
        "\n",
        "# # Convert class labels to numeric values\n",
        "# data['class'] = data['class'].map({'suicide': 1, 'non-suicide': 0})\n",
        "\n",
        "# # Extract true labels\n",
        "# true_labels = data['class']\n",
        "\n",
        "# # Example predicted labels (replace this with the predicted labels from your model)\n",
        "# # Here, I'm just assuming all predictions are non-suicidal (0) for demonstration purposes\n",
        "# predicted_labels = np.zeros(len(data))\n",
        "\n",
        "# print(\"True Labels:\", true_labels)\n",
        "# print(\"Predicted Labels:\", predicted_labels)\n",
        "\n",
        "# # Create confusion matrix\n",
        "# cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# # Plot confusion matrix (same as before)\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.colorbar()\n",
        "# classes = ['Non-Suicidal', 'Suicidal']\n",
        "# tick_marks = np.arange(len(classes))\n",
        "# plt.xticks(tick_marks, classes, rotation=45)\n",
        "# plt.yticks(tick_marks, classes)\n",
        "# plt.xlabel('Predicted Label')\n",
        "# plt.ylabel('True Label')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Example accuracy scores (replace this with your actual accuracy scores)\n",
        "# accuracy_scores = [0.75, 0.80, 0.85, 0.90, 0.92]\n",
        "\n",
        "# # Generate x-axis values (epochs or iterations)\n",
        "# epochs = range(1, len(accuracy_scores) + 1)\n",
        "\n",
        "# # Plot the accuracy graph\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.plot(epochs, accuracy_scores, marker='o', linestyle='-')\n",
        "# plt.title('Model Accuracy Over Time')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.xticks(epochs)\n",
        "# plt.grid(True)\n",
        "# plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
